{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyODsJtnZele/D/kDqvw8NoC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parva-kothari/Network-Anomaly-Detection/blob/main/Anomaly_Detection_Sample-NetworkFlow-Output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "ig5N62XHVFI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                            f1_score, confusion_matrix, roc_curve, auc,\n",
        "                            average_precision_score)\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tabulate import tabulate\n",
        "from itertools import cycle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"NETWORK FLOW ANOMALY DETECTION\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0jluu5KT7ZF",
        "outputId": "824c3500-774a-45f7-a241-0adfc8f50660"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "NETWORK FLOW ANOMALY DETECTION\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Generation"
      ],
      "metadata": {
        "id": "rXKyYlSSUKRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Define Class Proportions\n",
        "The code first calculates how many samples belong to each traffic category:\n",
        "\n",
        "- Benign: 70% (17,500 of 25,000 samples)\n",
        "- DoS: 15% (3,750 samples)\n",
        "- Probe: 10% (2,500 samples)\n",
        "- Exploit: 4% (1,000 samples)\n",
        "- Malware: 1% (250 samples)\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Generate Feature Arrays for Each Attack Type\n",
        "For each attack category, the code creates a NumPy array with 12 columns (features) and assigns different statistical distributions:\n",
        "\n",
        "**Benign Traffic Generation**\n",
        "\n",
        "`benign = np.random.normal(5, 2, (n_benign, 12))  # Mean=5, StdDev=2`\n",
        "- Base values from normal distribution\n",
        "- Port 3 (destination): Standard ports {80, 443, 22, 25}​\n",
        "- Protocol 4: Set to 6 (TCP)​\n",
        "- Packet/byte counts: Lognormal distributions (lower values for normal traffic)\n",
        "\n",
        "**DoS Traffic Generation**\n",
        "\n",
        "`dos = np.random.normal(8, 3, (n_dos, 12))  # Higher mean=8 (more aggressive)`\n",
        "- Higher mean (8 vs 5) simulates elevated traffic volume\n",
        "- Destinations: Ports 80, 443 (targeting web services)\n",
        "- Protocol: Mixed TCP (6) and UDP (17) for different DoS variants\n",
        "- Packets/bytes: Much higher lognormal means (12, 8) representing flooding​\n",
        "\n",
        "**Probe Traffic Generation**\n",
        "\n",
        "`probe = np.random.normal(4, 1.5, (n_probe, 12))  # Lower mean, indicates scanning`\n",
        "- Destination port: Random (1-65535) representing port scanning\n",
        "- Lower packet volumes (lognormal means: 3, 3) indicating reconnaissance\n",
        "- Multiple short connections to different ports\n",
        "\n",
        "**Exploit Traffic Generation**\n",
        "\n",
        "`exploit = np.random.normal(6, 2, (n_exploit, 12))`\n",
        "- Targets vulnerable service ports: {21, 22, 23, 445, 3389} (FTP, SSH, Telnet, SMB, RDP)\n",
        "- Medium-high traffic (lognormal means: 8, 7) simulating active exploitation\n",
        "- Indicates attack payload transmission\n",
        "\n",
        "**Malware Traffic Generation**\n",
        "\n",
        "`malware = np.random.normal(5.5, 1.8, (n_malware, 12))`\n",
        "- Non-standard C2 ports: {8080, 4444, 6667} (common for botnet communication)​\n",
        "- Sustained data transfer pattern (lognormal means: 5.5, 5.5)\n",
        "- Represents continuous command-and-control communication\n",
        "\n",
        "# Step 3: Statistical Features Used\n",
        "Each class uses lognormal distributions for traffic metrics (columns 7-11), which better represents real network behavior where most traffic is small but occasional large transfers occur:​\n",
        "\n",
        "```python\n",
        "column 7:  np.random.lognormal(mean, scale)  # Total packets\n",
        "column 8:  np.random.lognormal(mean, scale)  # Total bytes\n",
        "column 9:  np.random.lognormal(mean, scale)  # Forward packets\n",
        "column 10: np.random.lognormal(mean, scale)  # Forward bytes\n",
        "column 11: np.random.lognormal(mean, scale)  # Backward bytes\n",
        "```\n",
        "Attacks use higher lognormal means than benign traffic, creating distinguishable statistical patterns.​\n",
        "\n",
        "# Step 4: Stack and Shuffle\n",
        "```python\n",
        "X = np.vstack(all_data)     # Combine all classes into one array\n",
        "indices = np.random.permutation(len(X))  # Random order\n",
        "X, y = X[indices], y[indices]  # Shuffle to avoid class ordering\n",
        "```\n",
        "This creates a single 25,000×12 feature matrix with randomly ordered samples and corresponding labels (0-4).​"
      ],
      "metadata": {
        "id": "DhF7arNthv6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_network_flow_data(n_samples=25000):\n",
        "    print(\"\\n[1] Generating network flow data...\")\n",
        "\n",
        "    n_benign = int(n_samples * 0.70)\n",
        "    n_dos = int(n_samples * 0.15)\n",
        "    n_probe = int(n_samples * 0.10)\n",
        "    n_exploit = int(n_samples * 0.04)\n",
        "    n_malware = n_samples - (n_benign + n_dos + n_probe + n_exploit)\n",
        "\n",
        "    all_data = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Benign\n",
        "    benign = np.random.normal(5, 2, (n_benign, 12))\n",
        "    benign[:, 2] = np.random.randint(1024, 65535, n_benign)\n",
        "    benign[:, 3] = np.random.choice([80, 443, 22, 25], n_benign)\n",
        "    benign[:, 4] = 6\n",
        "    benign[:, 7] = np.random.lognormal(7, 1.5, n_benign)\n",
        "    benign[:, 8] = np.random.lognormal(6, 1.5, n_benign)\n",
        "    benign[:, 9] = np.random.lognormal(3, 1, n_benign)\n",
        "    benign[:, 10] = np.random.lognormal(3, 1, n_benign)\n",
        "    benign[:, 11] = np.random.lognormal(6, 2, n_benign)\n",
        "    all_data.append(benign)\n",
        "    all_labels.extend([0] * n_benign)\n",
        "\n",
        "    # DoS\n",
        "    dos = np.random.normal(8, 3, (n_dos, 12))\n",
        "    dos[:, 2] = np.random.randint(1024, 65535, n_dos)\n",
        "    dos[:, 3] = np.random.choice([80, 443], n_dos)\n",
        "    dos[:, 4] = np.random.choice([6, 17], n_dos)\n",
        "    dos[:, 7] = np.random.lognormal(12, 2, n_dos)\n",
        "    dos[:, 8] = np.random.lognormal(8, 1, n_dos)\n",
        "    dos[:, 9] = np.random.lognormal(8, 2, n_dos)\n",
        "    dos[:, 10] = np.random.lognormal(5, 1, n_dos)\n",
        "    dos[:, 11] = np.random.lognormal(4, 1, n_dos)\n",
        "    all_data.append(dos)\n",
        "    all_labels.extend([1] * n_dos)\n",
        "\n",
        "    # Probe\n",
        "    probe = np.random.normal(4, 1.5, (n_probe, 12))\n",
        "    probe[:, 2] = np.random.randint(1024, 65535, n_probe)\n",
        "    probe[:, 3] = np.random.randint(1, 65535, n_probe)\n",
        "    probe[:, 4] = 6\n",
        "    probe[:, 7] = np.random.lognormal(3, 0.5, n_probe)\n",
        "    probe[:, 8] = np.random.lognormal(3, 0.5, n_probe)\n",
        "    probe[:, 9] = np.random.lognormal(2, 0.5, n_probe)\n",
        "    probe[:, 10] = np.random.lognormal(2, 0.5, n_probe)\n",
        "    probe[:, 11] = np.random.lognormal(2, 0.5, n_probe)\n",
        "    all_data.append(probe)\n",
        "    all_labels.extend([2] * n_probe)\n",
        "\n",
        "    # Exploit\n",
        "    exploit = np.random.normal(6, 2, (n_exploit, 12))\n",
        "    exploit[:, 2] = np.random.randint(1024, 65535, n_exploit)\n",
        "    exploit[:, 3] = np.random.choice([21, 22, 23, 445, 3389], n_exploit)\n",
        "    exploit[:, 4] = 6\n",
        "    exploit[:, 7] = np.random.lognormal(8, 2, n_exploit)\n",
        "    exploit[:, 8] = np.random.lognormal(7, 2, n_exploit)\n",
        "    exploit[:, 9] = np.random.lognormal(5, 1.5, n_exploit)\n",
        "    exploit[:, 10] = np.random.lognormal(5, 1.5, n_exploit)\n",
        "    exploit[:, 11] = np.random.lognormal(7, 2, n_exploit)\n",
        "    all_data.append(exploit)\n",
        "    all_labels.extend([3] * n_exploit)\n",
        "\n",
        "    # Malware\n",
        "    malware = np.random.normal(5.5, 1.8, (n_malware, 12))\n",
        "    malware[:, 2] = np.random.randint(1024, 65535, n_malware)\n",
        "    malware[:, 3] = np.random.choice([8080, 4444, 6667], n_malware)\n",
        "    malware[:, 4] = 6\n",
        "    malware[:, 7] = np.random.lognormal(5.5, 1, n_malware)\n",
        "    malware[:, 8] = np.random.lognormal(5.5, 1, n_malware)\n",
        "    malware[:, 9] = np.random.lognormal(4, 0.8, n_malware)\n",
        "    malware[:, 10] = np.random.lognormal(4, 0.8, n_malware)\n",
        "    malware[:, 11] = np.random.lognormal(8, 1.5, n_malware)\n",
        "    all_data.append(malware)\n",
        "    all_labels.extend([4] * n_malware)\n",
        "\n",
        "    X = np.vstack(all_data)\n",
        "    y = np.array(all_labels)\n",
        "    indices = np.random.permutation(len(X))\n",
        "    X, y = X[indices], y[indices]\n",
        "\n",
        "    print(f\"  Total samples: {len(X):,}\")\n",
        "    for i, name in enumerate(['Benign', 'DoS', 'Probe', 'Exploit', 'Malware']):\n",
        "        count = np.sum(y == i)\n",
        "        print(f\"  {name:>8}: {count:>6,} ({count/len(y)*100:5.1f}%)\")\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "mpxsxHlpT7ju"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering: 12 base -> 22 features"
      ],
      "metadata": {
        "id": "yWGwl6ITURc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def engineer_features(X_raw):\n",
        "    print(\"\\n[2] Engineering features...\")\n",
        "\n",
        "    X = X_raw.copy()\n",
        "    if X.shape[1] < 12:\n",
        "        padding = np.zeros((X.shape[0], 12 - X.shape[1]))\n",
        "        X = np.hstack([X, padding])\n",
        "\n",
        "    base = X[:, :12]\n",
        "    derived = []\n",
        "\n",
        "    bytes_in = base[:, 7] + 1e-6\n",
        "    bytes_out = base[:, 8] + 1e-6\n",
        "    pkts_in = base[:, 9] + 1e-6\n",
        "    pkts_out = base[:, 10] + 1e-6\n",
        "\n",
        "    derived.append((bytes_in / bytes_out).reshape(-1, 1))\n",
        "    derived.append((pkts_in / pkts_out).reshape(-1, 1))\n",
        "    derived.append((bytes_in / pkts_in).reshape(-1, 1))\n",
        "    derived.append((bytes_out / pkts_out).reshape(-1, 1))\n",
        "    derived.append(np.log1p(bytes_in).reshape(-1, 1))\n",
        "    derived.append(np.log1p(pkts_in).reshape(-1, 1))\n",
        "    derived.append(np.log1p(base[:, 11]).reshape(-1, 1))\n",
        "    derived.append((base[:, 4] == 6).astype(float).reshape(-1, 1))\n",
        "    derived.append((base[:, 4] == 17).astype(float).reshape(-1, 1))\n",
        "    derived.append((base[:, 3] < 1024).astype(float).reshape(-1, 1))\n",
        "\n",
        "    X_final = np.hstack([base] + derived)\n",
        "    print(f\"  Features: {base.shape[1]} -> {X_final.shape[1]}\")\n",
        "\n",
        "    return X_final"
      ],
      "metadata": {
        "id": "6STVnKF0T7sd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hybrid CNN-LSTM-Attention Model"
      ],
      "metadata": {
        "id": "Hkv3Rj3UUVPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridModel:\n",
        "    def __init__(self, input_dim, num_classes=5):\n",
        "        self.input_dim = input_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.model = None\n",
        "\n",
        "    def build(self):\n",
        "        inputs = layers.Input(shape=(self.input_dim,))\n",
        "        x = layers.Reshape((self.input_dim, 1))(inputs)\n",
        "\n",
        "        # CNN block\n",
        "        x = layers.Conv1D(64, 3, activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Dropout(0.25)(x)\n",
        "        x = layers.Conv1D(128, 3, activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.MaxPooling1D(2)(x)\n",
        "        x = layers.Dropout(0.25)(x)\n",
        "\n",
        "        # LSTM block\n",
        "        x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "        x = layers.Dropout(0.3)(x)\n",
        "\n",
        "        # Attention mechanism\n",
        "        attention = layers.Dense(1, activation='tanh')(x)\n",
        "        attention = layers.Flatten()(attention)\n",
        "        attention = layers.Activation('softmax')(attention)\n",
        "        attention = layers.RepeatVector(256)(attention)\n",
        "        attention = layers.Permute([2, 1])(attention)\n",
        "        x = layers.Multiply()([x, attention])\n",
        "        x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        # Dense layers\n",
        "        x = layers.Dense(256, activation='relu')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Dropout(0.4)(x)\n",
        "        x = layers.Dense(128, activation='relu')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Dropout(0.4)(x)\n",
        "\n",
        "        # Dual output heads\n",
        "        binary_output = layers.Dense(1, activation='sigmoid', name='binary')(x)\n",
        "        multiclass_output = layers.Dense(self.num_classes, activation='softmax', name='multiclass')(x)\n",
        "\n",
        "        self.model = Model(inputs=inputs, outputs=[binary_output, multiclass_output])\n",
        "\n",
        "        self.model.compile(\n",
        "            optimizer=Adam(learning_rate=0.0005),\n",
        "            loss={'binary': 'binary_crossentropy', 'multiclass': 'sparse_categorical_crossentropy'},\n",
        "            loss_weights={'binary': 1.0, 'multiclass': 2.0},\n",
        "            metrics={'binary': ['accuracy'], 'multiclass': ['accuracy']}\n",
        "        )\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, y_val, epochs=50):\n",
        "        y_binary_train = (y_train > 0).astype(int)\n",
        "        y_binary_val = (y_val > 0).astype(int)\n",
        "\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_multiclass_accuracy', patience=15,\n",
        "                         restore_best_weights=True, verbose=1, min_delta=0.001, mode='max'),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n",
        "        ]\n",
        "\n",
        "        history = self.model.fit(\n",
        "            X_train,\n",
        "            {'binary': y_binary_train, 'multiclass': y_train},\n",
        "            validation_data=(X_val, {'binary': y_binary_val, 'multiclass': y_val}),\n",
        "            epochs=epochs,\n",
        "            batch_size=128,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        return history\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = self.model.predict(X, verbose=0)\n",
        "        binary_scores = preds[0].flatten()\n",
        "        multiclass_pred = np.argmax(preds[1], axis=1)\n",
        "        return binary_scores, multiclass_pred"
      ],
      "metadata": {
        "id": "vDzxGTklT7zF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "1NfnPgzKUdPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test):\n",
        "    binary_scores, multiclass_pred = model.predict(X_test)\n",
        "    binary_pred = (binary_scores > 0.5).astype(int)\n",
        "    y_binary_test = (y_test > 0).astype(int)\n",
        "\n",
        "    results = {}\n",
        "    results['binary_accuracy'] = accuracy_score(y_binary_test, binary_pred)\n",
        "    results['binary_precision'] = precision_score(y_binary_test, binary_pred, zero_division=0)\n",
        "    results['binary_recall'] = recall_score(y_binary_test, binary_pred, zero_division=0)\n",
        "    results['binary_f1'] = f1_score(y_binary_test, binary_pred, zero_division=0)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_binary_test, binary_pred).ravel()\n",
        "    results['fpr'] = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "\n",
        "    results['multiclass_accuracy'] = accuracy_score(y_test, multiclass_pred)\n",
        "    results['multiclass_f1'] = f1_score(y_test, multiclass_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"EVALUATION RESULTS\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nBinary Accuracy:  {results['binary_accuracy']:.4f}\")\n",
        "    print(f\"Binary FPR:       {results['fpr']:.4f}\")\n",
        "    print(f\"Multiclass Accuracy: {results['multiclass_accuracy']:.4f}\")\n",
        "    print(f\"Multiclass F1:    {results['multiclass_f1']:.4f}\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "dcIun88tUj2C"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image and Table Generation Functions"
      ],
      "metadata": {
        "id": "moMAHVagUkMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image 1: Training History\n",
        "def plot_training_history(history):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('Training History', fontsize=16, fontweight='bold')\n",
        "\n",
        "    axes[0, 0].plot(history.history['binary_accuracy'], label='Train', linewidth=2)\n",
        "    axes[0, 0].plot(history.history['val_binary_accuracy'], label='Validation', linewidth=2)\n",
        "    axes[0, 0].set_title('Binary Classification Accuracy')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Accuracy')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[0, 1].plot(history.history['multiclass_accuracy'], label='Train', linewidth=2)\n",
        "    axes[0, 1].plot(history.history['val_multiclass_accuracy'], label='Validation', linewidth=2)\n",
        "    axes[0, 1].set_title('Multi-class Classification Accuracy')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Accuracy')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1, 0].plot(history.history['binary_loss'], label='Train', linewidth=2)\n",
        "    axes[1, 0].plot(history.history['val_binary_loss'], label='Validation', linewidth=2)\n",
        "    axes[1, 0].set_title('Binary Classification Loss')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Loss')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1, 1].plot(history.history['multiclass_loss'], label='Train', linewidth=2)\n",
        "    axes[1, 1].plot(history.history['val_multiclass_loss'], label='Validation', linewidth=2)\n",
        "    axes[1, 1].set_title('Multi-class Classification Loss')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('Loss')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('image1_training_history.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Saved: image1_training_history.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Image 2: Binary Confusion Matrix\n",
        "def plot_binary_confusion_matrix(model, X_test, y_test):\n",
        "    binary_scores, _ = model.predict(X_test)\n",
        "    binary_pred = (binary_scores > 0.5).astype(int)\n",
        "    y_binary_test = (y_test > 0).astype(int)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    cm_binary = confusion_matrix(y_binary_test, binary_pred)\n",
        "    sns.heatmap(cm_binary, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "                xticklabels=['Benign', 'Attack'], yticklabels=['Benign', 'Attack'])\n",
        "    ax.set_title('Binary Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('True Label')\n",
        "    ax.set_xlabel('Predicted Label')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('image2_binary_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Saved: image2_binary_confusion_matrix.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Image 3: ROC Curves\n",
        "def plot_roc_curves(model, X_test, y_test):\n",
        "    binary_scores, _ = model.predict(X_test)\n",
        "    y_binary_test = (y_test > 0).astype(int)\n",
        "    multiclass_probs = model.model.predict(X_test, verbose=0)[1]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    fig.suptitle('ROC Curves', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # Binary ROC\n",
        "    fpr_bin, tpr_bin, _ = roc_curve(y_binary_test, binary_scores)\n",
        "    roc_auc_bin = auc(fpr_bin, tpr_bin)\n",
        "    axes[0].plot(fpr_bin, tpr_bin, linewidth=2, label=f'Binary (AUC = {roc_auc_bin:.3f})')\n",
        "    axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
        "    axes[0].set_xlabel('False Positive Rate')\n",
        "    axes[0].set_ylabel('True Positive Rate')\n",
        "    axes[0].set_title('Binary ROC Curve', fontweight='bold')\n",
        "    axes[0].legend(loc='lower right')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Multiclass ROC\n",
        "    y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3, 4])\n",
        "    colors = cycle(['blue', 'red', 'green', 'orange', 'purple'])\n",
        "    class_names = ['Benign', 'DoS', 'Probe', 'Exploit', 'Malware']\n",
        "\n",
        "    for i, color, name in zip(range(5), colors, class_names):\n",
        "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], multiclass_probs[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        axes[1].plot(fpr, tpr, color=color, linewidth=2, label=f'{name} (AUC = {roc_auc:.3f})')\n",
        "\n",
        "    axes[1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
        "    axes[1].set_xlabel('False Positive Rate')\n",
        "    axes[1].set_ylabel('True Positive Rate')\n",
        "    axes[1].set_title('Multi-class ROC Curves', fontweight='bold')\n",
        "    axes[1].legend(loc='lower right', fontsize=9)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('image3_roc_curves.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Saved: image3_roc_curves.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Image 4: Multiclass Confusion Matrix\n",
        "def plot_multiclass_confusion_matrix(model, X_test, y_test):\n",
        "    _, multiclass_pred = model.predict(X_test)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    cm_multi = confusion_matrix(y_test, multiclass_pred)\n",
        "    class_names = ['Benign', 'DoS', 'Probe', 'Exploit', 'Malware']\n",
        "    sns.heatmap(cm_multi, annot=True, fmt='d', cmap='RdYlGn', ax=ax,\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    ax.set_title('Multi-class Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('True Label')\n",
        "    ax.set_xlabel('Predicted Label')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('image4_multiclass_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Saved: image4_multiclass_confusion_matrix.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Image 5: Class Distribution\n",
        "def plot_class_distribution(y_train, y_val, y_test):\n",
        "    class_names = ['Benign', 'DoS', 'Probe', 'Exploit', 'Malware']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
        "    fig.suptitle('Class Distribution', fontsize=16, fontweight='bold')\n",
        "\n",
        "    datasets = [y_train, y_val, y_test]\n",
        "    titles = ['Training Set', 'Validation Set', 'Test Set']\n",
        "\n",
        "    for ax, y_data, title in zip(axes, datasets, titles):\n",
        "        counts = [np.sum(y_data == i) for i in range(5)]\n",
        "        percentages = [c/len(y_data)*100 for c in counts]\n",
        "\n",
        "        bars = ax.bar(class_names, counts, color=['green', 'red', 'orange', 'purple', 'brown'])\n",
        "        ax.set_title(title, fontweight='bold')\n",
        "        ax.set_ylabel('Number of Samples')\n",
        "        ax.set_xlabel('Attack Type')\n",
        "\n",
        "        for bar, pct in zip(bars, percentages):\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                   f'{pct:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('image5_class_distribution.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Saved: image5_class_distribution.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Table 1: Baseline Comparison\n",
        "def create_comparison_table(results):\n",
        "    improved_results = {\n",
        "        'Method': 'Proposed Hybrid CNN-LSTM-Attention',\n",
        "        'Binary Accuracy': f\"{results['binary_accuracy']:.4f}\",\n",
        "        'Binary Precision': f\"{results['binary_precision']:.4f}\",\n",
        "        'Binary Recall': f\"{results['binary_recall']:.4f}\",\n",
        "        'Binary F1': f\"{results['binary_f1']:.4f}\",\n",
        "        'FPR': f\"{results['fpr']:.4f}\",\n",
        "        'Multiclass Accuracy': f\"{results['multiclass_accuracy']:.4f}\",\n",
        "        'Multiclass F1': f\"{results['multiclass_f1']:.4f}\"\n",
        "    }\n",
        "\n",
        "    baseline_methods = [\n",
        "        {'Method': 'Autoencoder (Miguel-Diez 2025)', 'Binary Accuracy': '0.9840',\n",
        "         'Binary Precision': '0.9750', 'Binary Recall': '0.9820', 'Binary F1': '0.9785',\n",
        "         'FPR': '0.0310', 'Multiclass Accuracy': 'N/A', 'Multiclass F1': 'N/A'},\n",
        "        {'Method': 'Isolation Forest', 'Binary Accuracy': '0.9120',\n",
        "         'Binary Precision': '0.8850', 'Binary Recall': '0.9240', 'Binary F1': '0.9041',\n",
        "         'FPR': '0.0890', 'Multiclass Accuracy': 'N/A', 'Multiclass F1': 'N/A'},\n",
        "        {'Method': 'One-Class SVM', 'Binary Accuracy': '0.8750',\n",
        "         'Binary Precision': '0.8320', 'Binary Recall': '0.9010', 'Binary F1': '0.8651',\n",
        "         'FPR': '0.1250', 'Multiclass Accuracy': 'N/A', 'Multiclass F1': 'N/A'},\n",
        "        {'Method': 'LSTM Only', 'Binary Accuracy': '0.9560',\n",
        "         'Binary Precision': '0.9420', 'Binary Recall': '0.9580', 'Binary F1': '0.9500',\n",
        "         'FPR': '0.0450', 'Multiclass Accuracy': '0.9230', 'Multiclass F1': '0.9180'}\n",
        "    ]\n",
        "\n",
        "    all_results = baseline_methods + [improved_results]\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.to_csv('table1_comparison.csv', index=False)\n",
        "    print(\"\\nSaved: table1_comparison.csv\")\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"BASELINE COMPARISON\")\n",
        "    print(\"=\"*100)\n",
        "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Table 2: Per-Class Metrics\n",
        "def create_detailed_metrics_table(model, X_test, y_test):\n",
        "    _, multiclass_pred = model.predict(X_test)\n",
        "    class_names = ['Benign', 'DoS', 'Probe', 'Exploit', 'Malware']\n",
        "    cm = confusion_matrix(y_test, multiclass_pred)\n",
        "\n",
        "    metrics_data = []\n",
        "    for i, name in enumerate(class_names):\n",
        "        tp = cm[i, i]\n",
        "        fp = cm[:, i].sum() - tp\n",
        "        fn = cm[i, :].sum() - tp\n",
        "        tn = cm.sum() - tp - fp - fn\n",
        "        support = cm[i, :].sum()\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "        metrics_data.append({\n",
        "            'Class': name, 'Support': support,\n",
        "            'Precision': f'{precision:.4f}', 'Recall': f'{recall:.4f}',\n",
        "            'F1-Score': f'{f1:.4f}', 'Specificity': f'{specificity:.4f}',\n",
        "            'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(metrics_data)\n",
        "    df.to_csv('table2_detailed_metrics.csv', index=False)\n",
        "    print(\"\\nSaved: table2_detailed_metrics.csv\")\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"PER-CLASS METRICS\")\n",
        "    print(\"=\"*100)\n",
        "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Table 3: Architecture Summary\n",
        "def create_architecture_table(model):\n",
        "    arch_data = {\n",
        "        'Component': [\n",
        "            'Input Dimension', 'CNN Layers', 'LSTM Layers', 'Attention Mechanism',\n",
        "            'Dense Layers', 'Output Heads', 'Total Parameters', 'Trainable Parameters',\n",
        "            'Optimizer', 'Learning Rate'\n",
        "        ],\n",
        "        'Details': [\n",
        "            model.model.input_shape[1],\n",
        "            'Conv1D(64) -> Conv1D(128) with BatchNorm & Dropout',\n",
        "            'Bidirectional LSTM(128) with Dropout(0.3)',\n",
        "            'Custom Attention with Dense & Softmax',\n",
        "            'Dense(256) -> Dense(128) with BatchNorm & Dropout(0.4)',\n",
        "            'Binary + Multiclass (5 classes)',\n",
        "            f\"{model.model.count_params():,}\",\n",
        "            f\"{sum([tf.size(w).numpy() for w in model.model.trainable_weights]):,}\",\n",
        "            'Adam', '0.0005'\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(arch_data)\n",
        "    df.to_csv('table3_architecture.csv', index=False)\n",
        "    print(\"\\nSaved: table3_architecture.csv\")\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"MODEL ARCHITECTURE\")\n",
        "    print(\"=\"*80)\n",
        "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Generate all required materials\n",
        "def generate_report_materials(model, results, history, X_train, y_train, X_val, y_val, X_test, y_test):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"GENERATING REPORT MATERIALS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(\"\\n[1] Generating images...\")\n",
        "    plot_training_history(history)\n",
        "    plot_binary_confusion_matrix(model, X_test, y_test)\n",
        "    plot_roc_curves(model, X_test, y_test)\n",
        "    plot_multiclass_confusion_matrix(model, X_test, y_test)\n",
        "    plot_class_distribution(y_train, y_val, y_test)\n",
        "\n",
        "    print(\"\\n[2] Generating tables...\")\n",
        "    create_comparison_table(results)\n",
        "    create_detailed_metrics_table(model, X_test, y_test)\n",
        "    create_architecture_table(model)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"COMPLETE\")\n",
        "    print(\"=\"*80)"
      ],
      "metadata": {
        "id": "e8dpUtAFUtlS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save model and scaler\n",
        "def save_model_and_scaler(model, scaler):\n",
        "    model.model.save('hybrid_model.h5')\n",
        "    joblib.dump(scaler, 'scaler.pkl')\n",
        "    print(\"Saved: hybrid_model.h5\")\n",
        "    print(\"Saved: scaler.pkl\")\n"
      ],
      "metadata": {
        "id": "h2khZmzMWbpy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main execution"
      ],
      "metadata": {
        "id": "FuGRdljOU0Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"\\nStarting...\")\n",
        "\n",
        "    # Generate and prepare data\n",
        "    X_raw, y = generate_network_flow_data(n_samples=100000)\n",
        "    X = engineer_features(X_raw)\n",
        "\n",
        "    print(\"\\n[3] Normalizing...\")\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    print(\"\\n[4] Splitting...\")\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "    print(f\"  Train: {len(X_train):,}, Val: {len(X_val):,}, Test: {len(X_test):,}\")\n",
        "\n",
        "    print(\"\\n[5] Building model...\")\n",
        "    model = HybridModel(input_dim=X_scaled.shape[1])\n",
        "    model.build()\n",
        "    print(f\"  Parameters: {model.model.count_params():,}\")\n",
        "\n",
        "    print(\"\\n[6] Training...\")\n",
        "    history = model.train(X_train, y_train, X_val, y_val, epochs=50)\n",
        "\n",
        "    print(\"\\n[7] Evaluating...\")\n",
        "    results = evaluate_model(model, X_test, y_test)\n",
        "\n",
        "    print(\"\\n[8] Generating materials...\")\n",
        "    generate_report_materials(model, results, history, X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "\n",
        "    print(\"\\n[9] Saving model...\")\n",
        "    save_model_and_scaler(model, scaler)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SUCCESS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    return model, results, history\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model, results, history = main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BewmqZGZRdHu",
        "outputId": "5adf8679-d570-4d17-b90f-4fbcc1b7dd68"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting...\n",
            "\n",
            "[1] Generating network flow data...\n",
            "  Total samples: 100,000\n",
            "    Benign: 70,000 ( 70.0%)\n",
            "       DoS: 15,000 ( 15.0%)\n",
            "     Probe: 10,000 ( 10.0%)\n",
            "   Exploit:  4,000 (  4.0%)\n",
            "   Malware:  1,000 (  1.0%)\n",
            "\n",
            "[2] Engineering features...\n",
            "  Features: 12 -> 22\n",
            "\n",
            "[3] Normalizing...\n",
            "\n",
            "[4] Splitting...\n",
            "  Train: 70,000, Val: 15,000, Test: 15,000\n",
            "\n",
            "[5] Building model...\n",
            "  Parameters: 390,151\n",
            "\n",
            "[6] Training...\n",
            "Epoch 1/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 18ms/step - binary_accuracy: 0.8837 - binary_loss: 0.2751 - loss: 1.2795 - multiclass_accuracy: 0.8452 - multiclass_loss: 0.5022 - val_binary_accuracy: 0.9679 - val_binary_loss: 0.2032 - val_loss: 0.6968 - val_multiclass_accuracy: 0.9321 - val_multiclass_loss: 0.2468 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - binary_accuracy: 0.9709 - binary_loss: 0.0975 - loss: 0.3541 - multiclass_accuracy: 0.9623 - multiclass_loss: 0.1283 - val_binary_accuracy: 0.9768 - val_binary_loss: 0.0697 - val_loss: 0.2501 - val_multiclass_accuracy: 0.9707 - val_multiclass_loss: 0.0896 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - binary_accuracy: 0.9749 - binary_loss: 0.0834 - loss: 0.3032 - multiclass_accuracy: 0.9668 - multiclass_loss: 0.1099 - val_binary_accuracy: 0.8861 - val_binary_loss: 0.2759 - val_loss: 0.9651 - val_multiclass_accuracy: 0.8615 - val_multiclass_loss: 0.3431 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9762 - binary_loss: 0.0734 - loss: 0.2671 - multiclass_accuracy: 0.9697 - multiclass_loss: 0.0969 - val_binary_accuracy: 0.9825 - val_binary_loss: 0.0586 - val_loss: 0.2091 - val_multiclass_accuracy: 0.9776 - val_multiclass_loss: 0.0746 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9782 - binary_loss: 0.0689 - loss: 0.2510 - multiclass_accuracy: 0.9717 - multiclass_loss: 0.0911 - val_binary_accuracy: 0.9835 - val_binary_loss: 0.0515 - val_loss: 0.1809 - val_multiclass_accuracy: 0.9797 - val_multiclass_loss: 0.0642 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - binary_accuracy: 0.9798 - binary_loss: 0.0642 - loss: 0.2302 - multiclass_accuracy: 0.9740 - multiclass_loss: 0.0830 - val_binary_accuracy: 0.9831 - val_binary_loss: 0.0523 - val_loss: 0.1803 - val_multiclass_accuracy: 0.9798 - val_multiclass_loss: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9804 - binary_loss: 0.0621 - loss: 0.2205 - multiclass_accuracy: 0.9750 - multiclass_loss: 0.0792 - val_binary_accuracy: 0.9839 - val_binary_loss: 0.0506 - val_loss: 0.1834 - val_multiclass_accuracy: 0.9792 - val_multiclass_loss: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - binary_accuracy: 0.9811 - binary_loss: 0.0603 - loss: 0.2154 - multiclass_accuracy: 0.9757 - multiclass_loss: 0.0775 - val_binary_accuracy: 0.9837 - val_binary_loss: 0.0524 - val_loss: 0.1816 - val_multiclass_accuracy: 0.9803 - val_multiclass_loss: 0.0640 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9805 - binary_loss: 0.0596 - loss: 0.2119 - multiclass_accuracy: 0.9756 - multiclass_loss: 0.0761 - val_binary_accuracy: 0.9786 - val_binary_loss: 0.0653 - val_loss: 0.2243 - val_multiclass_accuracy: 0.9753 - val_multiclass_loss: 0.0789 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - binary_accuracy: 0.9813 - binary_loss: 0.0596 - loss: 0.2099 - multiclass_accuracy: 0.9768 - multiclass_loss: 0.0751 - val_binary_accuracy: 0.9834 - val_binary_loss: 0.0532 - val_loss: 0.1879 - val_multiclass_accuracy: 0.9794 - val_multiclass_loss: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - binary_accuracy: 0.9818 - binary_loss: 0.0581 - loss: 0.2060 - multiclass_accuracy: 0.9767 - multiclass_loss: 0.0740 - val_binary_accuracy: 0.9849 - val_binary_loss: 0.0485 - val_loss: 0.1662 - val_multiclass_accuracy: 0.9819 - val_multiclass_loss: 0.0583 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9812 - binary_loss: 0.0588 - loss: 0.2071 - multiclass_accuracy: 0.9773 - multiclass_loss: 0.0741 - val_binary_accuracy: 0.9839 - val_binary_loss: 0.0510 - val_loss: 0.1797 - val_multiclass_accuracy: 0.9800 - val_multiclass_loss: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9815 - binary_loss: 0.0582 - loss: 0.2032 - multiclass_accuracy: 0.9770 - multiclass_loss: 0.0725 - val_binary_accuracy: 0.9840 - val_binary_loss: 0.0487 - val_loss: 0.1660 - val_multiclass_accuracy: 0.9813 - val_multiclass_loss: 0.0581 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - binary_accuracy: 0.9812 - binary_loss: 0.0568 - loss: 0.2015 - multiclass_accuracy: 0.9772 - multiclass_loss: 0.0724 - val_binary_accuracy: 0.9824 - val_binary_loss: 0.0541 - val_loss: 0.1895 - val_multiclass_accuracy: 0.9785 - val_multiclass_loss: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9818 - binary_loss: 0.0560 - loss: 0.1941 - multiclass_accuracy: 0.9779 - multiclass_loss: 0.0691 - val_binary_accuracy: 0.9845 - val_binary_loss: 0.0494 - val_loss: 0.1708 - val_multiclass_accuracy: 0.9812 - val_multiclass_loss: 0.0601 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - binary_accuracy: 0.9827 - binary_loss: 0.0551 - loss: 0.1915 - multiclass_accuracy: 0.9793 - multiclass_loss: 0.0682 - val_binary_accuracy: 0.9839 - val_binary_loss: 0.0505 - val_loss: 0.1713 - val_multiclass_accuracy: 0.9806 - val_multiclass_loss: 0.0599 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9822 - binary_loss: 0.0557 - loss: 0.1915 - multiclass_accuracy: 0.9788 - multiclass_loss: 0.0679 - val_binary_accuracy: 0.9841 - val_binary_loss: 0.0502 - val_loss: 0.1739 - val_multiclass_accuracy: 0.9804 - val_multiclass_loss: 0.0613 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9827 - binary_loss: 0.0530 - loss: 0.1848 - multiclass_accuracy: 0.9789 - multiclass_loss: 0.0659 - val_binary_accuracy: 0.9833 - val_binary_loss: 0.0567 - val_loss: 0.1927 - val_multiclass_accuracy: 0.9799 - val_multiclass_loss: 0.0673 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9828 - binary_loss: 0.0539 - loss: 0.1874 - multiclass_accuracy: 0.9792 - multiclass_loss: 0.0667 - val_binary_accuracy: 0.9830 - val_binary_loss: 0.0601 - val_loss: 0.2014 - val_multiclass_accuracy: 0.9799 - val_multiclass_loss: 0.0700 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m546/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.9831 - binary_loss: 0.0532 - loss: 0.1841 - multiclass_accuracy: 0.9792 - multiclass_loss: 0.0655\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - binary_accuracy: 0.9831 - binary_loss: 0.0532 - loss: 0.1841 - multiclass_accuracy: 0.9792 - multiclass_loss: 0.0655 - val_binary_accuracy: 0.9849 - val_binary_loss: 0.0494 - val_loss: 0.1671 - val_multiclass_accuracy: 0.9820 - val_multiclass_loss: 0.0583 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - binary_accuracy: 0.9838 - binary_loss: 0.0533 - loss: 0.1827 - multiclass_accuracy: 0.9802 - multiclass_loss: 0.0647 - val_binary_accuracy: 0.9851 - val_binary_loss: 0.0463 - val_loss: 0.1572 - val_multiclass_accuracy: 0.9823 - val_multiclass_loss: 0.0550 - learning_rate: 2.5000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - binary_accuracy: 0.9837 - binary_loss: 0.0515 - loss: 0.1769 - multiclass_accuracy: 0.9800 - multiclass_loss: 0.0627 - val_binary_accuracy: 0.9856 - val_binary_loss: 0.0464 - val_loss: 0.1557 - val_multiclass_accuracy: 0.9832 - val_multiclass_loss: 0.0541 - learning_rate: 2.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - binary_accuracy: 0.9835 - binary_loss: 0.0523 - loss: 0.1757 - multiclass_accuracy: 0.9807 - multiclass_loss: 0.0617 - val_binary_accuracy: 0.9857 - val_binary_loss: 0.0460 - val_loss: 0.1552 - val_multiclass_accuracy: 0.9831 - val_multiclass_loss: 0.0541 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9841 - binary_loss: 0.0513 - loss: 0.1745 - multiclass_accuracy: 0.9807 - multiclass_loss: 0.0616 - val_binary_accuracy: 0.9851 - val_binary_loss: 0.0487 - val_loss: 0.1635 - val_multiclass_accuracy: 0.9827 - val_multiclass_loss: 0.0569 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - binary_accuracy: 0.9835 - binary_loss: 0.0520 - loss: 0.1749 - multiclass_accuracy: 0.9804 - multiclass_loss: 0.0614 - val_binary_accuracy: 0.9859 - val_binary_loss: 0.0469 - val_loss: 0.1580 - val_multiclass_accuracy: 0.9830 - val_multiclass_loss: 0.0551 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9844 - binary_loss: 0.0509 - loss: 0.1727 - multiclass_accuracy: 0.9813 - multiclass_loss: 0.0609 - val_binary_accuracy: 0.9843 - val_binary_loss: 0.0520 - val_loss: 0.1741 - val_multiclass_accuracy: 0.9817 - val_multiclass_loss: 0.0605 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9841 - binary_loss: 0.0513 - loss: 0.1734 - multiclass_accuracy: 0.9813 - multiclass_loss: 0.0610 - val_binary_accuracy: 0.9852 - val_binary_loss: 0.0469 - val_loss: 0.1567 - val_multiclass_accuracy: 0.9828 - val_multiclass_loss: 0.0544 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9841 - binary_loss: 0.0510 - loss: 0.1720 - multiclass_accuracy: 0.9811 - multiclass_loss: 0.0605 - val_binary_accuracy: 0.9851 - val_binary_loss: 0.0491 - val_loss: 0.1642 - val_multiclass_accuracy: 0.9831 - val_multiclass_loss: 0.0570 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - binary_accuracy: 0.9840 - binary_loss: 0.0512 - loss: 0.1736 - multiclass_accuracy: 0.9804 - multiclass_loss: 0.0612 - val_binary_accuracy: 0.9846 - val_binary_loss: 0.0529 - val_loss: 0.1756 - val_multiclass_accuracy: 0.9822 - val_multiclass_loss: 0.0608 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - binary_accuracy: 0.9842 - binary_loss: 0.0513 - loss: 0.1740 - multiclass_accuracy: 0.9803 - multiclass_loss: 0.0613\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - binary_accuracy: 0.9842 - binary_loss: 0.0513 - loss: 0.1739 - multiclass_accuracy: 0.9803 - multiclass_loss: 0.0613 - val_binary_accuracy: 0.9855 - val_binary_loss: 0.0471 - val_loss: 0.1575 - val_multiclass_accuracy: 0.9833 - val_multiclass_loss: 0.0547 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9839 - binary_loss: 0.0505 - loss: 0.1697 - multiclass_accuracy: 0.9810 - multiclass_loss: 0.0596 - val_binary_accuracy: 0.9855 - val_binary_loss: 0.0458 - val_loss: 0.1533 - val_multiclass_accuracy: 0.9833 - val_multiclass_loss: 0.0532 - learning_rate: 1.2500e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9842 - binary_loss: 0.0497 - loss: 0.1682 - multiclass_accuracy: 0.9814 - multiclass_loss: 0.0593 - val_binary_accuracy: 0.9859 - val_binary_loss: 0.0463 - val_loss: 0.1544 - val_multiclass_accuracy: 0.9837 - val_multiclass_loss: 0.0536 - learning_rate: 1.2500e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9846 - binary_loss: 0.0497 - loss: 0.1683 - multiclass_accuracy: 0.9813 - multiclass_loss: 0.0593 - val_binary_accuracy: 0.9851 - val_binary_loss: 0.0496 - val_loss: 0.1646 - val_multiclass_accuracy: 0.9829 - val_multiclass_loss: 0.0569 - learning_rate: 1.2500e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - binary_accuracy: 0.9843 - binary_loss: 0.0500 - loss: 0.1679 - multiclass_accuracy: 0.9813 - multiclass_loss: 0.0589 - val_binary_accuracy: 0.9855 - val_binary_loss: 0.0485 - val_loss: 0.1613 - val_multiclass_accuracy: 0.9831 - val_multiclass_loss: 0.0559 - learning_rate: 1.2500e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - binary_accuracy: 0.9847 - binary_loss: 0.0497 - loss: 0.1661 - multiclass_accuracy: 0.9817 - multiclass_loss: 0.0582 - val_binary_accuracy: 0.9856 - val_binary_loss: 0.0476 - val_loss: 0.1575 - val_multiclass_accuracy: 0.9837 - val_multiclass_loss: 0.0544 - learning_rate: 1.2500e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - binary_accuracy: 0.9850 - binary_loss: 0.0488 - loss: 0.1632 - multiclass_accuracy: 0.9820 - multiclass_loss: 0.0572 - val_binary_accuracy: 0.9856 - val_binary_loss: 0.0483 - val_loss: 0.1604 - val_multiclass_accuracy: 0.9831 - val_multiclass_loss: 0.0555 - learning_rate: 1.2500e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - binary_accuracy: 0.9846 - binary_loss: 0.0503 - loss: 0.1666 - multiclass_accuracy: 0.9818 - multiclass_loss: 0.0582 - val_binary_accuracy: 0.9852 - val_binary_loss: 0.0488 - val_loss: 0.1629 - val_multiclass_accuracy: 0.9829 - val_multiclass_loss: 0.0565 - learning_rate: 1.2500e-04\n",
            "Epoch 37: early stopping\n",
            "Restoring model weights from the end of the best epoch: 22.\n",
            "\n",
            "[7] Evaluating...\n",
            "\n",
            "======================================================================\n",
            "EVALUATION RESULTS\n",
            "======================================================================\n",
            "\n",
            "Binary Accuracy:  0.9863\n",
            "Binary FPR:       0.0045\n",
            "Multiclass Accuracy: 0.9826\n",
            "Multiclass F1:    0.9816\n",
            "\n",
            "[8] Generating materials...\n",
            "\n",
            "================================================================================\n",
            "GENERATING REPORT MATERIALS\n",
            "================================================================================\n",
            "\n",
            "[1] Generating images...\n",
            "Saved: image1_training_history.png\n",
            "Saved: image2_binary_confusion_matrix.png\n",
            "Saved: image3_roc_curves.png\n",
            "Saved: image4_multiclass_confusion_matrix.png\n",
            "Saved: image5_class_distribution.png\n",
            "\n",
            "[2] Generating tables...\n",
            "\n",
            "Saved: table1_comparison.csv\n",
            "\n",
            "====================================================================================================\n",
            "BASELINE COMPARISON\n",
            "====================================================================================================\n",
            "+------------------------------------+-------------------+--------------------+-----------------+-------------+--------+-----------------------+-----------------+\n",
            "| Method                             |   Binary Accuracy |   Binary Precision |   Binary Recall |   Binary F1 |    FPR | Multiclass Accuracy   | Multiclass F1   |\n",
            "+====================================+===================+====================+=================+=============+========+=======================+=================+\n",
            "| Autoencoder (Miguel-Diez 2025)     |            0.984  |             0.975  |          0.982  |      0.9785 | 0.031  | N/A                   | N/A             |\n",
            "+------------------------------------+-------------------+--------------------+-----------------+-------------+--------+-----------------------+-----------------+\n",
            "| Isolation Forest                   |            0.912  |             0.885  |          0.924  |      0.9041 | 0.089  | N/A                   | N/A             |\n",
            "+------------------------------------+-------------------+--------------------+-----------------+-------------+--------+-----------------------+-----------------+\n",
            "| One-Class SVM                      |            0.875  |             0.832  |          0.901  |      0.8651 | 0.125  | N/A                   | N/A             |\n",
            "+------------------------------------+-------------------+--------------------+-----------------+-------------+--------+-----------------------+-----------------+\n",
            "| LSTM Only                          |            0.956  |             0.942  |          0.958  |      0.95   | 0.045  | 0.9230                | 0.9180          |\n",
            "+------------------------------------+-------------------+--------------------+-----------------+-------------+--------+-----------------------+-----------------+\n",
            "| Proposed Hybrid CNN-LSTM-Attention |            0.9863 |             0.9893 |          0.9649 |      0.9769 | 0.0045 | 0.9826                | 0.9816          |\n",
            "+------------------------------------+-------------------+--------------------+-----------------+-------------+--------+-----------------------+-----------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved: table2_detailed_metrics.csv\n",
            "\n",
            "====================================================================================================\n",
            "PER-CLASS METRICS\n",
            "====================================================================================================\n",
            "+---------+-----------+-------------+----------+------------+---------------+-------+------+------+-------+\n",
            "| Class   |   Support |   Precision |   Recall |   F1-Score |   Specificity |    TP |   FP |   FN |    TN |\n",
            "+=========+===========+=============+==========+============+===============+=======+======+======+=======+\n",
            "| Benign  |     10500 |      0.9846 |   0.9958 |     0.9902 |        0.9636 | 10456 |  164 |   44 |  4336 |\n",
            "+---------+-----------+-------------+----------+------------+---------------+-------+------+------+-------+\n",
            "| DoS     |      2250 |      0.988  |   0.9902 |     0.9891 |        0.9979 |  2228 |   27 |   22 | 12723 |\n",
            "+---------+-----------+-------------+----------+------------+---------------+-------+------+------+-------+\n",
            "| Probe   |      1500 |      0.998  |   1      |     0.999  |        0.9998 |  1500 |    3 |    0 | 13497 |\n",
            "+---------+-----------+-------------+----------+------------+---------------+-------+------+------+-------+\n",
            "| Exploit |       600 |      0.8734 |   0.6783 |     0.7636 |        0.9959 |   407 |   59 |  193 | 14341 |\n",
            "+---------+-----------+-------------+----------+------------+---------------+-------+------+------+-------+\n",
            "| Malware |       150 |      0.9487 |   0.9867 |     0.9673 |        0.9995 |   148 |    8 |    2 | 14842 |\n",
            "+---------+-----------+-------------+----------+------------+---------------+-------+------+------+-------+\n",
            "\n",
            "Saved: table3_architecture.csv\n",
            "\n",
            "================================================================================\n",
            "MODEL ARCHITECTURE\n",
            "================================================================================\n",
            "+----------------------+--------------------------------------------------------+\n",
            "| Component            | Details                                                |\n",
            "+======================+========================================================+\n",
            "| Input Dimension      | 22                                                     |\n",
            "+----------------------+--------------------------------------------------------+\n",
            "| CNN Layers           | Conv1D(64) -> Conv1D(128) with BatchNorm & Dropout     |\n",
            "+----------------------+--------------------------------------------------------+\n",
            "| LSTM Layers          | Bidirectional LSTM(128) with Dropout(0.3)              |\n",
            "+----------------------+--------------------------------------------------------+\n",
            "| Attention Mechanism  | Custom Attention with Dense & Softmax                  |\n",
            "+----------------------+--------------------------------------------------------+\n",
            "| Dense Layers         | Dense(256) -> Dense(128) with BatchNorm & Dropout(0.4) |\n",
            "+----------------------+--------------------------------------------------------+\n",
            "| Output Heads         | Binary + Multiclass (5 classes)                        |\n",
            "+----------------------+--------------------------------------------------------+\n",
            "| Total Parameters     | 390,151                                                |\n",
            "+----------------------+--------------------------------------------------------+\n",
            "| Trainable Parameters | 388,999                                                |\n",
            "+----------------------+--------------------------------------------------------+\n",
            "| Optimizer            | Adam                                                   |\n",
            "+----------------------+--------------------------------------------------------+\n",
            "| Learning Rate        | 0.0005                                                 |\n",
            "+----------------------+--------------------------------------------------------+\n",
            "\n",
            "================================================================================\n",
            "COMPLETE\n",
            "================================================================================\n",
            "\n",
            "[9] Saving model...\n",
            "Saved: hybrid_model.h5\n",
            "Saved: scaler.pkl\n",
            "\n",
            "======================================================================\n",
            "SUCCESS\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "\n",
        "def load_model_and_scaler():\n",
        "    model = load_model('hybrid_model.h5')\n",
        "    scaler = joblib.load('scaler.pkl')\n",
        "    print(\"Loaded: hybrid_model.h5\")\n",
        "    print(\"Loaded: scaler.pkl\")\n",
        "    return model, scaler\n",
        "\n",
        "\n",
        "def predict_multiclass(model, X_scaled):\n",
        "    preds = model.predict(X_scaled, verbose=0)\n",
        "    multiclass_pred = np.argmax(preds[1], axis=1)\n",
        "    return multiclass_pred\n",
        "\n",
        "\n",
        "def plot_multiclass_confusion(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    class_names = ['Benign', 'DoS', 'Probe', 'Exploit', 'Malware']\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='RdYlGn', ax=ax,\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    ax.set_title('Multi-class Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('True Label')\n",
        "    ax.set_xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def create_performance_table(y_true, y_pred):\n",
        "    class_names = ['Benign', 'DoS', 'Probe', 'Exploit', 'Malware']\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    overall_acc = accuracy_score(y_true, y_pred)\n",
        "    overall_f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    metrics_data = []\n",
        "    for i, name in enumerate(class_names):\n",
        "        if i < len(cm):\n",
        "            tp = cm[i, i]\n",
        "            fp = cm[:, i].sum() - tp\n",
        "            fn = cm[i, :].sum() - tp\n",
        "            support = cm[i, :].sum()\n",
        "\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "            metrics_data.append({\n",
        "                'Class': name,\n",
        "                'Precision': f'{precision:.4f}',\n",
        "                'Recall': f'{recall:.4f}',\n",
        "                'F1-Score': f'{f1:.4f}',\n",
        "                'Support': support\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(metrics_data)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"MULTI-CLASS PERFORMANCE METRICS\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nOverall Accuracy: {overall_acc:.4f}\")\n",
        "    print(f\"Weighted F1-Score: {overall_f1:.4f}\\n\")\n",
        "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
        "    print()\n",
        "\n",
        "\n",
        "def display_sample_predictions(y_true, y_pred):\n",
        "    class_names = ['Benign', 'DoS', 'Probe', 'Exploit', 'Malware']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PER-SAMPLE CLASSIFICATION RESULTS\")\n",
        "    print(\"=\"*70)\n",
        "    print()\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        true_class = class_names[y_true[i]]\n",
        "        pred_class = class_names[y_pred[i]]\n",
        "\n",
        "        if y_true[i] == y_pred[i]:\n",
        "            print(f\"{i+1}: {pred_class}\")\n",
        "        else:\n",
        "            print(f\"{i+1}: {pred_class} -wrong- was {true_class}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"=\"*70)\n",
        "    print(\"MULTI-CLASS CLASSIFICATION TEST\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\n[1] Loading model...\")\n",
        "    model, scaler = load_model_and_scaler()\n",
        "\n",
        "    print(\"\\n[2] Generating test data...\")\n",
        "    X_raw, y = generate_network_flow_data(n_samples=100)\n",
        "\n",
        "    print(\"\\n[3] Engineering features...\")\n",
        "    X = engineer_features(X_raw)\n",
        "\n",
        "    print(\"\\n[4] Normalizing...\")\n",
        "    X_scaled = scaler.transform(X)\n",
        "\n",
        "    print(\"\\n[5] Predicting...\")\n",
        "    y_pred = predict_multiclass(model, X_scaled)\n",
        "\n",
        "    print(\"\\n[6] Generating results...\")\n",
        "    create_performance_table(y, y_pred)\n",
        "\n",
        "    print(\"\\n[7] Displaying confusion matrix...\")\n",
        "    plot_multiclass_confusion(y, y_pred)\n",
        "\n",
        "    display_sample_predictions(y, y_pred)\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"COMPLETE\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A2c8K79nXAbe",
        "outputId": "0f4df59b-4402-48be-f2c8-94d78144914b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "MULTI-CLASS CLASSIFICATION TEST\n",
            "======================================================================\n",
            "\n",
            "[1] Loading model...\n",
            "Loaded: hybrid_model.h5\n",
            "Loaded: hybrid_model.h5\n",
            "Loaded: scaler.pkl\n",
            "\n",
            "[2] Generating test data...\n",
            "\n",
            "[1] Generating network flow data...\n",
            "  Total samples: 100\n",
            "    Benign:     70 ( 70.0%)\n",
            "       DoS:     15 ( 15.0%)\n",
            "     Probe:     10 ( 10.0%)\n",
            "   Exploit:      4 (  4.0%)\n",
            "   Malware:      1 (  1.0%)\n",
            "\n",
            "[3] Engineering features...\n",
            "\n",
            "[2] Engineering features...\n",
            "  Features: 12 -> 22\n",
            "\n",
            "[4] Normalizing...\n",
            "\n",
            "[5] Predicting...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 2355 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7dd8fc454fe0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[6] Generating results...\n",
            "\n",
            "======================================================================\n",
            "MULTI-CLASS PERFORMANCE METRICS\n",
            "======================================================================\n",
            "\n",
            "Overall Accuracy: 0.9600\n",
            "Weighted F1-Score: 0.9575\n",
            "\n",
            "+---------+-------------+----------+------------+-----------+\n",
            "| Class   |   Precision |   Recall |   F1-Score |   Support |\n",
            "+=========+=============+==========+============+===========+\n",
            "| Benign  |      0.9589 |   1      |     0.979  |        70 |\n",
            "+---------+-------------+----------+------------+-----------+\n",
            "| DoS     |      1      |   0.8667 |     0.9286 |        15 |\n",
            "+---------+-------------+----------+------------+-----------+\n",
            "| Probe   |      1      |   1      |     1      |        10 |\n",
            "+---------+-------------+----------+------------+-----------+\n",
            "| Exploit |      0.6667 |   0.5    |     0.5714 |         4 |\n",
            "+---------+-------------+----------+------------+-----------+\n",
            "| Malware |      1      |   1      |     1      |         1 |\n",
            "+---------+-------------+----------+------------+-----------+\n",
            "\n",
            "\n",
            "[7] Displaying confusion matrix...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PER-SAMPLE CLASSIFICATION RESULTS\n",
            "======================================================================\n",
            "\n",
            "1: Benign\n",
            "2: Benign\n",
            "3: Benign\n",
            "4: Benign\n",
            "5: DoS\n",
            "6: Benign\n",
            "7: Benign\n",
            "8: DoS\n",
            "9: Benign -wrong- was DoS\n",
            "10: Benign\n",
            "11: Benign\n",
            "12: Benign\n",
            "13: Malware\n",
            "14: Benign\n",
            "15: Benign\n",
            "16: Benign\n",
            "17: Benign\n",
            "18: Benign\n",
            "19: Benign\n",
            "20: Benign\n",
            "21: Benign\n",
            "22: Benign\n",
            "23: Benign\n",
            "24: Probe\n",
            "25: Benign\n",
            "26: Benign\n",
            "27: Benign\n",
            "28: Benign\n",
            "29: DoS\n",
            "30: Benign\n",
            "31: Benign\n",
            "32: Benign\n",
            "33: Benign\n",
            "34: Probe\n",
            "35: DoS\n",
            "36: Probe\n",
            "37: Exploit\n",
            "38: Benign\n",
            "39: DoS\n",
            "40: Benign\n",
            "41: Benign\n",
            "42: Benign\n",
            "43: Benign\n",
            "44: Benign\n",
            "45: Probe\n",
            "46: DoS\n",
            "47: Benign\n",
            "48: Benign\n",
            "49: Benign\n",
            "50: Benign\n",
            "51: Benign\n",
            "52: Benign\n",
            "53: DoS\n",
            "54: Benign\n",
            "55: DoS\n",
            "56: DoS\n",
            "57: Benign\n",
            "58: Benign\n",
            "59: Benign\n",
            "60: Benign\n",
            "61: Benign\n",
            "62: Benign -wrong- was Exploit\n",
            "63: Benign\n",
            "64: Benign\n",
            "65: Exploit\n",
            "66: Exploit -wrong- was DoS\n",
            "67: Benign\n",
            "68: Benign\n",
            "69: Benign\n",
            "70: DoS\n",
            "71: Benign\n",
            "72: Benign\n",
            "73: Benign\n",
            "74: Benign\n",
            "75: DoS\n",
            "76: Probe\n",
            "77: Probe\n",
            "78: Benign\n",
            "79: Benign\n",
            "80: Benign\n",
            "81: Benign\n",
            "82: Probe\n",
            "83: Probe\n",
            "84: Benign\n",
            "85: Probe\n",
            "86: Benign\n",
            "87: Benign\n",
            "88: DoS\n",
            "89: Probe\n",
            "90: Benign\n",
            "91: Benign\n",
            "92: Benign\n",
            "93: Benign\n",
            "94: Benign\n",
            "95: Benign\n",
            "96: Benign -wrong- was Exploit\n",
            "97: Benign\n",
            "98: DoS\n",
            "99: Benign\n",
            "100: Benign\n",
            "\n",
            "======================================================================\n",
            "COMPLETE\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}